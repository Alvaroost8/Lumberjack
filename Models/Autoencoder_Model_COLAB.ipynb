{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi_4BN7MMFoV"
      },
      "source": [
        "# **Autoencoder Model - Anomaly Detection**\n",
        "### Group 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO8EE6VrMFoX"
      },
      "source": [
        "### **__Comments__**\n",
        "\n",
        "- Need to fix the DataLoading tensors\n",
        "\n",
        "- **Model without finetuning**\n",
        "\n",
        "- Model was a basic autoencoder architecture (could be tuned further)\n",
        "\n",
        "- Evaluation methods need to be explored further\n",
        "\n",
        "- Batch size was chosen as 64 because of it being the standard should be changed\n",
        "\n",
        "- We need to create the (normalized) score values for the logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "f9fW07fCMFoX"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure we are using GPU to train the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "FusRm4QTMwIO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "fUY9oGQBMFoY",
        "outputId": "2d9c91ea-042d-41c8-9bfb-0e14d07865c3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Unterminated string starting at: line 1 column 57671678 (char 57671677)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c6baa7c7214f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the json file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/features.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Unterminated string starting at: line 1 column 57671678 (char 57671677)"
          ]
        }
      ],
      "source": [
        "# Load the json file\n",
        "features = open(\"/content/features.json\")\n",
        "data_dict=json.load(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data-frame and exploration**"
      ],
      "metadata": {
        "id": "-gKTwe3FNDKb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw9lUfRqMFoY"
      },
      "outputs": [],
      "source": [
        "def time_diff(features):\n",
        "    for ip in features:\n",
        "        for i in range(len(features[ip])):\n",
        "            log_time=list(features[ip][i][\"log_time\"])\n",
        "            if(i==0):\n",
        "                features[ip][i][\"time_diff\"]=-1\n",
        "            else:\n",
        "                if((log_time[0]-features[ip][i-1][\"log_time\"][0])<0):\n",
        "                    features[ip][i][\"time_diff\"]=-1\n",
        "                else:\n",
        "                    time_diff=0\n",
        "                    if((log_time[2]-features[ip][i-1][\"log_time\"][2])<0):\n",
        "                        log_time[2]+=60\n",
        "                        log_time[1]-=1\n",
        "                    time_diff+=log_time[2]-features[ip][i-1][\"log_time\"][2]\n",
        "                    if((log_time[1]-features[ip][i-1][\"log_time\"][1])<0):\n",
        "                        log_time[1]+=60\n",
        "                        log_time[0]-=1\n",
        "                    time_diff+=(log_time[1]-features[ip][i-1][\"log_time\"][1])*60\n",
        "                    time_diff+=(log_time[0]-features[ip][i-1][\"log_time\"][0])*3600\n",
        "                    if(time_diff<0):\n",
        "                        features[ip][i][\"time_diff\"]=-1\n",
        "                    else:\n",
        "                        features[ip][i][\"time_diff\"]=time_diff\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIJaFSPuMFoZ"
      },
      "outputs": [],
      "source": [
        "data_dict=time_diff(data_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IlU7nKeMFoZ"
      },
      "outputs": [],
      "source": [
        "l_ip=[]\n",
        "l_lon=[]\n",
        "l_lat=[]\n",
        "l_time=[]\n",
        "l_time_diff=[]\n",
        "l_inst=[]\n",
        "l_url=[]\n",
        "l_response=[]\n",
        "l_weight=[]\n",
        "for i in data_dict.keys():\n",
        "    for log in data_dict[i]:\n",
        "        l_ip.append(i)\n",
        "        l_lat.append(log[\"coords\"][0])\n",
        "        l_lon.append(log[\"coords\"][1])\n",
        "        l_time.append(log[\"log_time\"])\n",
        "        l_time_diff.append(log[\"time_diff\"])\n",
        "        l_inst.append(log[\"instruction\"])\n",
        "        l_url.append(log[\"url\"])\n",
        "        l_response.append(log[\"response\"])\n",
        "        l_weight.append(log[\"response_weight\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTNITVbfMFoZ"
      },
      "outputs": [],
      "source": [
        "for i in range(len(l_time)):\n",
        "    l_time[i]=l_time[i][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKAGDKJGMFoZ"
      },
      "outputs": [],
      "source": [
        "l_ip=pd.Series(l_ip)\n",
        "l_lat=pd.Series(l_lat)\n",
        "l_lon=pd.Series(l_lon)\n",
        "l_time=pd.Series(l_time)\n",
        "l_inst=pd.Series(l_inst)\n",
        "l_url=pd.Series(l_url)\n",
        "l_response=pd.Series(l_response)\n",
        "l_weight=pd.Series(l_weight)\n",
        "\n",
        "\n",
        "# Some data exploration\n",
        "print(l_ip[0]) # 35.170.74.25\n",
        "print(l_lat[0]) # 22.3193\n",
        "print(l_lon[0]) # 40.7128\n",
        "print(l_time[0]) # 18\n",
        "print(l_inst[0]) # HEAD\n",
        "print(l_url[0]) # /fr/que-faire/que-fer-sitges-de-nit.htm HTTP/2.0\n",
        "print(l_response[0]) # 200\n",
        "print(l_weight[0]) # 9037\n",
        "\n",
        "\n",
        "print(l_ip.dtype) # object\n",
        "print(l_lat.dtype) # float64\n",
        "print(l_lon.dtype) # float64\n",
        "print(l_time.dtype) # int64\n",
        "print(l_inst.dtype) # object\n",
        "print(l_url.dtype) # object\n",
        "print(l_response.dtype) # object\n",
        "print(l_weight.dtype) # object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wNZQ4GLMFoa"
      },
      "outputs": [],
      "source": [
        "# Data-frame creation\n",
        "frame = {\"IP\": l_ip,\"Lat\":l_lat,\"Lon\":l_lon,\"Time\":l_time,\"Time Diff\":l_time_diff,\"Instruction\":l_inst,\"URL\":l_url,\"Response\":l_response,\"Weight\":l_weight}\n",
        "data=pd.DataFrame(frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zscq9M3pMFoa"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSNNe9zNMFoa"
      },
      "source": [
        "**Model Pipeline & Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKAOtvfGMFob"
      },
      "outputs": [],
      "source": [
        "# One-hot encode categorical features and standardize numerical features\n",
        "ct = ColumnTransformer(transformers=[\n",
        "    (\"encoder\", OneHotEncoder(), [\"Instruction\", \"URL\"]),\n",
        "    (\"scaler\", StandardScaler(), [\"Lat\", \"Lon\", \"Time\", \"Time Diff\", \"Response\", \"Weight\"])\n",
        "])\n",
        "\n",
        "data_encoded = pd.DataFrame(ct.fit_transform(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4IrV7sSMFob"
      },
      "outputs": [],
      "source": [
        "# Split data into train and test sets classic 80/20 split\n",
        "train_data, test_data = train_test_split(data_encoded, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjfrKKjeMFob"
      },
      "outputs": [],
      "source": [
        "# Define the autoencoder architecture\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 16)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(16, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwlps_XYMFob"
      },
      "source": [
        "**Dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-O6Nv7uMFob"
      },
      "outputs": [],
      "source": [
        "# Convert data to PyTorch tensors\n",
        "train_data_tensor = torch.tensor(train_data.values, dtype=torch.float32)\n",
        "test_data_tensor = torch.tensor(test_data.values, dtype=torch.float32)\n",
        "\n",
        "# Define DataLoader\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_data_tensor, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTCkm1OdMFob"
      },
      "source": [
        "**Model Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdYLkNuAMFob"
      },
      "outputs": [],
      "source": [
        "# Initialize the autoencoder model\n",
        "input_dim = train_data.shape[1]\n",
        "autoencoder = Autoencoder(input_dim)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgNCnIAyMFob"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHOaMZFHMFob"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for data in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = autoencoder(data)\n",
        "        loss = criterion(outputs, data)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIegmOCIMFob"
      },
      "source": [
        "**Evaluation & Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2Tg35mrMFoc"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model (we can use reconstruction error as anomaly score, but we still have to normalize it etc )\n",
        "with torch.no_grad():\n",
        "    reconstructions = autoencoder(test_data_tensor)\n",
        "    reconstruction_loss = criterion(reconstructions, test_data_tensor)\n",
        "    print(f\"Reconstruction Loss: {reconstruction_loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJRupByQMFoc"
      },
      "outputs": [],
      "source": [
        "# Some visualization\n",
        "\n",
        "# Calculate reconstruction error for each data point\n",
        "reconstruction_errors = torch.mean((reconstructions - test_data_tensor)**2, dim=1).detach().numpy()\n",
        "\n",
        "# Plot the distribution of reconstruction errors\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(reconstruction_errors, bins=50, alpha=0.5, color='blue', label=\"Reconstruction Errors\")\n",
        "plt.axvline(np.mean(reconstruction_errors), color='red', linestyle='dashed', linewidth=1, label=\"Mean Error\")\n",
        "plt.xlabel(\"Reconstruction Error\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Log Reconstruction Errors\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}